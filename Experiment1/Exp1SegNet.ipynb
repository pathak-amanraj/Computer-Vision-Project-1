{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10710910,"sourceType":"datasetVersion","datasetId":6638551}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (Input, SeparableConv2D, MaxPooling2D, \n                                     GlobalAveragePooling2D, Dense, BatchNormalization, Dropout)\nfrom sklearn.metrics import precision_recall_curve\n\n# Set dataset paths\ndataset_path = \"/kaggle/input/plantvillage-dataset/data_distribution_for_SVM\"\n\n# Load dataset and split into Train/Validation/Test\nall_images, all_labels = [], []\nlabel_map = {str(i): i for i in range(38)}\n\ntrain_folder = os.path.join(dataset_path, \"train\")\nfor label in os.listdir(train_folder):\n    label_path = os.path.join(train_folder, label)\n    for img_file in os.listdir(label_path):\n        all_images.append(os.path.join(label_path, img_file))\n        all_labels.append(label_map[label])\n\ntrain_imgs, val_imgs, train_labels, val_labels = train_test_split(\n    all_images, all_labels, test_size=0.25, stratify=all_labels, random_state=42\n)\n\ntest_imgs, test_labels = [], []\ntest_folder = os.path.join(dataset_path, \"test\")\nfor label in os.listdir(test_folder):\n    label_path = os.path.join(test_folder, label)\n    for img_file in os.listdir(label_path):\n        test_imgs.append(os.path.join(label_path, img_file))\n        test_labels.append(label_map[label])\n\n# Compute class weights\nclass_weights = compute_class_weight(\"balanced\", classes=np.unique(all_labels), y=all_labels)\nclass_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n\n# Convert labels to strings\ntrain_labels = list(map(str, train_labels))\nval_labels = list(map(str, val_labels))\ntest_labels = list(map(str, test_labels))\n\ndatagen = ImageDataGenerator(rescale=1.0/255)\ntrain_gen = datagen.flow_from_dataframe(\n    pd.DataFrame({\"filename\": train_imgs, \"class\": train_labels}),\n    x_col=\"filename\", y_col=\"class\", target_size=(224, 224), batch_size=64, class_mode=\"sparse\")\nval_gen = datagen.flow_from_dataframe(\n    pd.DataFrame({\"filename\": val_imgs, \"class\": val_labels}),\n    x_col=\"filename\", y_col=\"class\", target_size=(224, 224), batch_size=64, class_mode=\"sparse\")\ntest_gen = datagen.flow_from_dataframe(\n    pd.DataFrame({\"filename\": test_imgs, \"class\": test_labels}),\n    x_col=\"filename\", y_col=\"class\", target_size=(224, 224), batch_size=64, class_mode=\"sparse\", shuffle=False)\n\n# Define optimized SegNet-based classifier\ndef build_optimized_segnet_classifier(input_shape=(224, 224, 3), num_classes=38):\n    inputs = Input(shape=input_shape)\n\n    x = SeparableConv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n\n    x = SeparableConv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n\n    x = SeparableConv2D(128, (3, 3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n\n    x = GlobalAveragePooling2D()(x)\n\n    x = Dense(128, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.4)(x)\n    \n    out = Dense(num_classes, activation='softmax')(x)\n    \n    model = Model(inputs, out)\n    return model\n\nmodel = build_optimized_segnet_classifier()\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train model\nhistory = model.fit(train_gen, validation_data=val_gen, epochs=10, class_weight=class_weight_dict)\n\n# Evaluate model\ntest_loss, test_accuracy = model.evaluate(test_gen)\nprint(\"Final Test Accuracy:\", test_accuracy)\n\n# Plot training/validation accuracy\nplt.figure(figsize=(10, 5))\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Training and Validation Accuracy')\nplt.show()\n\n# Compute and plot PR curve\ny_true = tf.keras.utils.to_categorical(test_gen.classes, 38)\ny_probs = model.predict(test_gen)\n\nplt.figure(figsize=(10, 6))\nfor i in range(38):\n    precision, recall, _ = precision_recall_curve(y_true[:, i], y_probs[:, i])\n    plt.plot(recall, precision, marker='.', label=f'Class {i}')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve for Each Class')\nplt.legend()\nplt.show()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}