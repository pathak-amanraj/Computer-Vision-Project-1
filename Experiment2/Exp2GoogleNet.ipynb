{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1091061,"sourceType":"datasetVersion","datasetId":608236}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport random\nimport albumentations as A\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetV2S\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import SGD\nfrom sklearn.metrics import precision_recall_curve\n\n\n# Set dataset paths\ndataset_path = \"/kaggle/input/thermal-images-diseased-healthy-leaves-paddy/thermal images UL\"\noutput_path = \"/kaggle/working/expanded_dataset\"\nfinal_dataset_path = \"/kaggle/working/final_processed_dataset\"\n\n# Ensure only valid labels are considered\nvalid_labels = {\"BLB\", \"Blast\", \"healthy\", \"hispa\", \"leaf folder\", \"leaf spot\"}\n\n# Create necessary directories\nos.makedirs(output_path, exist_ok=True)\nos.makedirs(final_dataset_path, exist_ok=True)\n\n# Define augmentations\naugmentations = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.Rotate(limit=45, p=0.5),\n    A.RandomBrightnessContrast(p=0.5),\n    A.GaussianBlur(p=0.3),\n    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.5),\n    A.RandomResizedCrop(height=200, width=200, scale=(0.7, 1.0), p=0.5),\n    A.GridDistortion(p=0.3),\n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.5)\n])\n\n# Define image processing functions\ndef apply_clahe(img):\n    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n    l, a, b = cv2.split(lab)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    l = clahe.apply(l)\n    return cv2.cvtColor(cv2.merge((l, a, b)), cv2.COLOR_LAB2BGR)\n\ndef apply_filtering(img):\n    return cv2.medianBlur(cv2.GaussianBlur(img, (5, 5), 0), 5)\n\ndef apply_thresholding(img):\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    return cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)\n\ndef apply_morphology(img):\n    kernel = np.ones((5, 5), np.uint8)\n    return cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n\n# Expand dataset to 220 images per label\nfor label in os.listdir(dataset_path):\n    if label not in valid_labels:\n        continue\n    label_path = os.path.join(dataset_path, label)\n    save_path = os.path.join(output_path, label)\n    os.makedirs(save_path, exist_ok=True)\n    \n    images = [os.path.join(label_path, img) for img in os.listdir(label_path)]\n    \n    while len(images) < 220:\n        img_path = random.choice(images)\n        img = cv2.imread(img_path)\n        augmented = augmentations(image=img)[\"image\"]\n        cv2.imwrite(os.path.join(save_path, f\"aug_{len(images)}.jpg\"), augmented)\n        images.append(img_path)\n\n# Apply Processing Techniques\nfor label in os.listdir(output_path):\n    if label not in valid_labels:\n        continue\n    label_path = os.path.join(output_path, label)\n    save_label_path = os.path.join(final_dataset_path, label)\n    os.makedirs(save_label_path, exist_ok=True)\n    \n    for img_file in os.listdir(label_path):\n        img_path = os.path.join(label_path, img_file)\n        img = cv2.imread(img_path)\n        \n        cv2.imwrite(os.path.join(save_label_path, f\"orig_{img_file}\"), img)\n        cv2.imwrite(os.path.join(save_label_path, f\"clahe_{img_file}\"), apply_clahe(img))\n        cv2.imwrite(os.path.join(save_label_path, f\"filtered_{img_file}\"), apply_filtering(img))\n        cv2.imwrite(os.path.join(save_label_path, f\"thresh_{img_file}\"), apply_thresholding(img))\n        cv2.imwrite(os.path.join(save_label_path, f\"morph_{img_file}\"), apply_morphology(img))\n\n# Load dataset and split into Train/Validation/Test\nall_images, all_labels = [], []\nlabel_map = {label: idx for idx, label in enumerate(valid_labels)}\n\nfor label in valid_labels:\n    label_path = os.path.join(final_dataset_path, label)\n    for img_file in os.listdir(label_path):\n        all_images.append(os.path.join(label_path, img_file))\n        all_labels.append(label_map[label])\n\ntrain_imgs, temp_imgs, train_labels, temp_labels = train_test_split(all_images, all_labels, test_size=0.4, stratify=all_labels, random_state=42)\nval_imgs, test_imgs, val_labels, test_labels = train_test_split(temp_imgs, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42)\n\n# Compute class weights\nclass_weights = compute_class_weight(\"balanced\", classes=np.unique(all_labels), y=all_labels)\nclass_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n\n# Convert labels to strings\ntrain_labels = list(map(str, train_labels))\nval_labels = list(map(str, val_labels))\ntest_labels = list(map(str, test_labels))\n\ndatagen = ImageDataGenerator(rescale=1.0/255)\ntrain_gen = datagen.flow_from_dataframe(pd.DataFrame({\"filename\": train_imgs, \"class\": train_labels}), x_col=\"filename\", y_col=\"class\", target_size=(224, 224), batch_size=32, class_mode=\"sparse\")\nval_gen = datagen.flow_from_dataframe(pd.DataFrame({\"filename\": val_imgs, \"class\": val_labels}), x_col=\"filename\", y_col=\"class\", target_size=(224, 224), batch_size=32, class_mode=\"sparse\")\ntest_gen = datagen.flow_from_dataframe(pd.DataFrame({\"filename\": test_imgs, \"class\": test_labels}), x_col=\"filename\", y_col=\"class\", target_size=(224, 224), batch_size=32, class_mode=\"sparse\", shuffle=False)\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout, Input, concatenate\nfrom tensorflow.keras.optimizers import SGD\n\n# Define Inception module\ndef inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj):\n    conv1x1 = Conv2D(filters_1x1, (1, 1), activation='relu', padding='same')(x)\n    \n    conv3x3_reduce = Conv2D(filters_3x3_reduce, (1, 1), activation='relu', padding='same')(x)\n    conv3x3 = Conv2D(filters_3x3, (3, 3), activation='relu', padding='same')(conv3x3_reduce)\n    \n    conv5x5_reduce = Conv2D(filters_5x5_reduce, (1, 1), activation='relu', padding='same')(x)\n    conv5x5 = Conv2D(filters_5x5, (5, 5), activation='relu', padding='same')(conv5x5_reduce)\n    \n    pool_proj = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    pool_proj = Conv2D(filters_pool_proj, (1, 1), activation='relu', padding='same')(pool_proj)\n    \n    output = concatenate([conv1x1, conv3x3, conv5x5, pool_proj], axis=-1)\n    return output\n\n# Define GoogleNet model\ninput_layer = Input(shape=(224, 224, 3))\n\n# Initial Convolutional Layers\nx = Conv2D(64, (7, 7), strides=2, activation='relu', padding='same')(input_layer)\nx = MaxPooling2D((3, 3), strides=2, padding='same')(x)\nx = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\nx = Conv2D(192, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((3, 3), strides=2, padding='same')(x)\n\n# Inception Modules\nx = inception_module(x, 64, 96, 128, 16, 32, 32)\nx = inception_module(x, 128, 128, 192, 32, 96, 64)\nx = MaxPooling2D((3, 3), strides=2, padding='same')(x)\n\nx = inception_module(x, 192, 96, 208, 16, 48, 64)\nx = inception_module(x, 160, 112, 224, 24, 64, 64)\nx = inception_module(x, 128, 128, 256, 24, 64, 64)\nx = inception_module(x, 112, 144, 288, 32, 64, 64)\nx = inception_module(x, 256, 160, 320, 32, 128, 128)\nx = MaxPooling2D((3, 3), strides=2, padding='same')(x)\n\nx = inception_module(x, 256, 160, 320, 32, 128, 128)\nx = inception_module(x, 384, 192, 384, 48, 128, 128)\nx = AveragePooling2D((7, 7), strides=1)(x)\n\n# Fully Connected Layers\nx = Flatten()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\noutput_layer = Dense(len(valid_labels), activation='softmax')(x)\n\n# Build Model\nmodel = Model(inputs=input_layer, outputs=output_layer)\n\n# Compile the model\nmodel.compile(optimizer=SGD(learning_rate=0.0007, momentum=0.9),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n\n# Train model\nhistory = model.fit(train_gen, validation_data=val_gen, epochs=20, class_weight=class_weight_dict)\n\n\n# Evaluate model on test data\ntest_loss, test_accuracy = model.evaluate(test_gen)\nprint(\"Final Test Accuracy:\", test_accuracy)\n\n# Plot training/validation accuracy\nplt.figure(figsize=(10, 5))\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Training and Validation Accuracy')\nplt.show()\n\n# Compute and plot PR curve\nnum_classes = len(valid_labels)\ny_true = tf.keras.utils.to_categorical(test_gen.classes, num_classes)\ny_probs = model.predict(test_gen)\n\nplt.figure(figsize=(10, 6))\nfor i in range(num_classes):\n    precision, recall, _ = precision_recall_curve(y_true[:, i], y_probs[:, i])\n    plt.plot(recall, precision, marker='.', label=f'Class {i}')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve for Each Class')\nplt.legend()\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}